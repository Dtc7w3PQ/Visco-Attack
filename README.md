Visco-Attack

📄 Paper: Visual Contextual Attack: Jailbreaking MLLMs with Image-Driven Context Injection
(arXiv:2507.02844)

<div align="center">
  <h2>
    <img src="assets/cyber-criminal.png" alt="RA Logo" width="32" style="vertical-align: middle; margin-right: 5px;" />
    VisCo-Attack: Visual Contextual Jailbreak Dataset
    <br><br>
    <a href="https://arxiv.org/abs/2507.02844">
        <img alt="paper link" src="https://img.shields.io/badge/Paper-arXiv-red?style=flat" />
    </a>
    <a href="https://huggingface.co/datasets/miaozq/Visco-Attack">
        <img alt="Dataset" src="https://img.shields.io/badge/HuggingFace-Visco--Attack-blue?style=flat" />
    </a>
    <a href="https://huggingface.co/datasets/miaozq/Visco-Attack">
        <img alt="HF Downloads" src="https://hfhub.dev/api/datasets/miaozq/Visco-Attack/badge.svg" />
    </a>
    <a href="https://github.com/Dtc7w3PQ/Visco-Attack">
        <img alt="GitHub Stars" src="https://img.shields.io/github/stars/Dtc7w3PQ/Visco-Attack?style=flat&logo=github" />
    </a>
  </h2>
</div>
⸻

📁 Dataset

The dataset is publicly available on Hugging Face:
🔗 https://huggingface.co/datasets/miaozq/Visco-Attack

⸻

💻 Code

🚧 Coming soon!
We are actively preparing the codebase for release. Stay tuned!
